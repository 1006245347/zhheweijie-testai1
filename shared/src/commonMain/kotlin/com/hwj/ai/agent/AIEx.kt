package com.hwj.ai.agent

import ai.koog.embeddings.local.LLMEmbedder
import ai.koog.prompt.llm.LLMCapability
import ai.koog.prompt.llm.LLMProvider
import ai.koog.prompt.llm.LLModel
import ai.koog.rag.vector.InMemoryDocumentEmbeddingStorage
import ai.koog.rag.vector.InMemoryTextDocumentEmbeddingStorage
import ai.koog.rag.vector.TextDocumentEmbedder
import com.hwj.ai.global.getCacheString

/**
 * @author by jason-ä½•ä¼Ÿæ°ï¼Œ2025/9/1
 * shared/
 * des:å¿«é€Ÿé›†æˆæ‰€æœ‰æ™ºèƒ½ä½“çš„å·¥å…·åº“å¯¹è±¡
 */

//ä¸“ä¸šå‘é‡åŒ–æœåŠ¡å¯¹è±¡   keyCall: suspend (String) -> String?
fun createLLMEmbedder(apiKey: String, llModel: LLModel = createEmbedLLM()): LLMEmbedder {
    val client = OpenAiRemoteLLMClient(apiKey = apiKey)
    val embedder = LLMEmbedder(client, llModel)
    return embedder
}

//ä¸“ç”¨å‘é‡åŒ–æ¨¡å‹
fun createEmbedLLM(modelId: String = "bge-gree"): LLModel {
    return LLModel(
        LLMProvider.OpenAI, modelId, capabilities = listOf(LLMCapability.Embed),
        contextLength = 128_000, maxOutputTokens = 16_384
    )
}

//è¦æ˜¯ä½ ç°åœ¨åœ¨åš å¤šå¹³å°çš„ RAG çŸ¥è¯†åº“ï¼Œæ¨èç”¨ InMemoryDocumentEmbeddingStorageï¼Œå› ä¸ºåç»­æ£€ç´¢æ—¶ä½ ä¼š
// éœ€è¦ metadataï¼ˆæ–‡ä»¶åã€æ¥æºé¡µç ç­‰ï¼‰ï¼Œå¦åˆ™ä½ åªèƒ½æ‹¿åˆ°â€œæŸæ®µæ–‡æœ¬â€ï¼Œæ²¡æ³•æº¯æºã€‚
//InMemoryTextDocumentEmbeddingStorage ğŸ‘‰ ç©å…·çº§ / åªç®¡å­˜ String
//InMemoryDocumentEmbeddingStorage ğŸ‘‰ ç”Ÿäº§çº§ / å­˜ Document + Metadata
fun cc() {
    val embed = createLLMEmbedder("")
    val documentProvider = TextDocumentEmbedder(AIDocumentProvider, embed)
//    val storage = InMemoryDocumentEmbeddingStorage(documentProvider)
//    val storage= InMemoryTextDocumentEmbeddingStorage(embed, AIDocumentProvider)
}


//åªæœ‰å†…å­˜å‘é‡å­˜å‚¨æ˜¯æ‰€æœ‰å¹³å°éƒ½æ”¯æŒï¼ŒiOSä¸æ”¯æŒJvmç±»å‹çš„storage
fun createMemoryStorage(embedder: LLMEmbedder) {
//    InMemoryTextDocumentEmbeddingStorage(embedder)
//    embedder.embed("")
//    InMemoryVectorStorage()
}





